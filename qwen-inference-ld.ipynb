{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall -y ninja && pip install ninja\n!ninja --version\n!echo $?","metadata":{"execution":{"iopub.status.busy":"2024-10-21T05:15:25.057242Z","iopub.execute_input":"2024-10-21T05:15:25.058112Z","iopub.status.idle":"2024-10-21T05:15:41.656424Z","shell.execute_reply.started":"2024-10-21T05:15:25.058070Z","shell.execute_reply":"2024-10-21T05:15:41.655240Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Found existing installation: ninja 1.11.1.1\nUninstalling ninja-1.11.1.1:\n  Successfully uninstalled ninja-1.11.1.1\nCollecting ninja\n  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\nDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: ninja\nSuccessfully installed ninja-1.11.1.1\n1.11.1.git.kitware.jobserver-1\n0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip uninstall torch -y\n!pip install torch==2.2.1 torchvision==0.17.1 torchaudio==2.2.1 --index-url https://download.pytorch.org/whl/cu118","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-21T05:15:41.658684Z","iopub.execute_input":"2024-10-21T05:15:41.659019Z","iopub.status.idle":"2024-10-21T05:18:09.198274Z","shell.execute_reply.started":"2024-10-21T05:15:41.658984Z","shell.execute_reply":"2024-10-21T05:18:09.197102Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found existing installation: torch 2.4.0\nUninstalling torch-2.4.0:\n  Successfully uninstalled torch-2.4.0\nLooking in indexes: https://download.pytorch.org/whl/cu118\nCollecting torch==2.2.1\n  Downloading https://download.pytorch.org/whl/cu118/torch-2.2.1%2Bcu118-cp310-cp310-linux_x86_64.whl (819.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.2/819.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchvision==0.17.1\n  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.17.1%2Bcu118-cp310-cp310-linux_x86_64.whl (6.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchaudio==2.2.1\n  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.2.1%2Bcu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.2.1) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.1) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.2.1) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.2.1) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.1) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.2.1) (2024.6.1)\nCollecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.2.1)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.2.1)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.2.1)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu11==8.7.0.84 (from torch==2.2.1)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl (728.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m728.5/728.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.2.1)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.2.1)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch==2.2.1)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.2.1)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.2.1)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu11==2.19.3 (from torch==2.2.1)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.19.3-py3-none-manylinux1_x86_64.whl (135.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch==2.2.1)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting triton==2.2.0 (from torch==2.2.1)\n  Downloading https://download.pytorch.org/whl/triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.17.1) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.17.1) (10.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.2.1) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.2.1) (1.3.0)\nInstalling collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.19.0\n    Uninstalling torchvision-0.19.0:\n      Successfully uninstalled torchvision-0.19.0\n  Attempting uninstall: torchaudio\n    Found existing installation: torchaudio 2.4.0\n    Uninstalling torchaudio-2.4.0:\n      Successfully uninstalled torchaudio-2.4.0\nSuccessfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.7.0.84 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.19.3 nvidia-nvtx-cu11-11.8.86 torch-2.2.1+cu118 torchaudio-2.2.1+cu118 torchvision-0.17.1+cu118 triton-2.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/transformers@21fac7abba2a37fae86106f87fcf9974fd1e3830 accelerate","metadata":{"execution":{"iopub.status.busy":"2024-10-21T05:18:09.199738Z","iopub.execute_input":"2024-10-21T05:18:09.200053Z","iopub.status.idle":"2024-10-21T05:19:08.684186Z","shell.execute_reply.started":"2024-10-21T05:18:09.200019Z","shell.execute_reply":"2024-10-21T05:19:08.683254Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/huggingface/transformers@21fac7abba2a37fae86106f87fcf9974fd1e3830\n  Cloning https://github.com/huggingface/transformers (to revision 21fac7abba2a37fae86106f87fcf9974fd1e3830) to /tmp/pip-req-build-cue4pbyq\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-cue4pbyq\n  Running command git rev-parse -q --verify 'sha^21fac7abba2a37fae86106f87fcf9974fd1e3830'\n  Running command git fetch -q https://github.com/huggingface/transformers 21fac7abba2a37fae86106f87fcf9974fd1e3830\n  Running command git checkout -q 21fac7abba2a37fae86106f87fcf9974fd1e3830\n  Resolved https://github.com/huggingface/transformers to commit 21fac7abba2a37fae86106f87fcf9974fd1e3830\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (2.32.3)\nCollecting tokenizers<0.20,>=0.19 (from transformers==4.45.0.dev0)\n  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.2.1+cu118)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.45.0.dev0) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.8.89)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.8.89)\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.8.87)\nRequirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.7.0.84)\nRequirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.11.3.6)\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.9.0.58)\nRequirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.0.86)\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.1.48)\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.5.86)\nRequirement already satisfied: nvidia-nccl-cu11==2.19.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.8.86)\nRequirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.45.0.dev0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.45.0.dev0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.45.0.dev0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.45.0.dev0) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers: filename=transformers-4.45.0.dev0-py3-none-any.whl size=9677030 sha256=5240698e9518d668fc2f98a6edf0ed63a51311c4ec589ded18071a02ab0a5b90\n  Stored in directory: /root/.cache/pip/wheels/28/41/24/cb082d58fae00708aaa217e3e6162526ba4d1f24f27e06b0bf\nSuccessfully built transformers\nInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.20.0\n    Uninstalling tokenizers-0.20.0:\n      Successfully uninstalled tokenizers-0.20.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.45.1\n    Uninstalling transformers-4.45.1:\n      Successfully uninstalled transformers-4.45.1\nSuccessfully installed tokenizers-0.19.1 transformers-4.45.0.dev0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install flash-attn==2.6.1 --no-build-isolation","metadata":{"execution":{"iopub.status.busy":"2024-10-21T05:19:08.687470Z","iopub.execute_input":"2024-10-21T05:19:08.688296Z","iopub.status.idle":"2024-10-21T05:19:35.665226Z","shell.execute_reply.started":"2024-10-21T05:19:08.688243Z","shell.execute_reply":"2024-10-21T05:19:35.664045Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting flash-attn==2.6.1\n  Downloading flash_attn-2.6.1.tar.gz (2.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.6.1) (2.2.1+cu118)\nCollecting einops (from flash-attn==2.6.1)\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.6.1) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.6.1) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.6.1) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.6.1) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.6.1) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.6.1) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.6.1) (11.8.89)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.6.1) (11.8.89)\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.6.1) (11.8.87)\nRequirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.6.1) (8.7.0.84)\nRequirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.6.1) (11.11.3.6)\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.6.1) (10.9.0.58)\nRequirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.6.1) (10.3.0.86)\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.6.1) (11.4.1.48)\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.6.1) (11.7.5.86)\nRequirement already satisfied: nvidia-nccl-cu11==2.19.3 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.6.1) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.6.1) (11.8.86)\nRequirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.6.1) (2.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn==2.6.1) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn==2.6.1) (1.3.0)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: flash-attn\n  Building wheel for flash-attn (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.6.1-cp310-cp310-linux_x86_64.whl size=199979967 sha256=d717cfdeff9d23d1ae6a3f4a1a90f629bec498873f7c20786093c37b990b9586\n  Stored in directory: /root/.cache/pip/wheels/91/6a/38/f0faa036b4ac73a73247386f1ab1bb4cb4f6e72e6861a779f1\nSuccessfully built flash-attn\nInstalling collected packages: einops, flash-attn\nSuccessfully installed einops-0.8.0 flash-attn-2.6.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install autoawq@https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl\n!pip install https://github.com/casper-hansen/AutoAWQ_kernels/releases/download/v0.0.6/autoawq_kernels-0.0.6+cu118-cp310-cp310-linux_x86_64.whl","metadata":{"execution":{"iopub.status.busy":"2024-10-21T05:19:35.666592Z","iopub.execute_input":"2024-10-21T05:19:35.666911Z","iopub.status.idle":"2024-10-21T05:20:02.498020Z","shell.execute_reply.started":"2024-10-21T05:19:35.666878Z","shell.execute_reply":"2024-10-21T05:20:02.497013Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl\n  Downloading https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl (84 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting autoawq-kernels@ https://github.com/casper-hansen/AutoAWQ_kernels/releases/download/v0.0.6/autoawq_kernels-0.0.6+cu118-cp310-cp310-linux_x86_64.whl (from autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl)\n  Downloading https://github.com/casper-hansen/AutoAWQ_kernels/releases/download/v0.0.6/autoawq_kernels-0.0.6+cu118-cp310-cp310-linux_x86_64.whl (33.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.0/33.0 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (2.2.1+cu118)\nRequirement already satisfied: transformers>=4.35.0 in /opt/conda/lib/python3.10/site-packages (from autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (4.45.0.dev0)\nRequirement already satisfied: tokenizers>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (0.19.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (4.12.2)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (0.34.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (3.0.1)\nRequirement already satisfied: zstandard in /opt/conda/lib/python3.10/site-packages (from autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (0.23.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers>=0.12.1->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (11.8.89)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (11.8.89)\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (11.8.87)\nRequirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (8.7.0.84)\nRequirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (11.11.3.6)\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (10.9.0.58)\nRequirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (10.3.0.86)\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (11.4.1.48)\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (11.7.5.86)\nRequirement already satisfied: nvidia-nccl-cu11==2.19.3 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (11.8.86)\nRequirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (2.2.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (5.9.3)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (3.9.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.35.0->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.35.0->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.35.0->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.35.0->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.35.0->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.0.1->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.0.1->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->autoawq@ https://github.com/casper-hansen/AutoAWQ/releases/download/v0.2.5/autoawq-0.2.5+cu118-cp310-cp310-linux_x86_64.whl) (1.16.0)\nInstalling collected packages: autoawq-kernels, autoawq\nSuccessfully installed autoawq-0.2.5+cu118 autoawq-kernels-0.0.6+cu118\nCollecting autoawq-kernels==0.0.6+cu118\n  Using cached https://github.com/casper-hansen/AutoAWQ_kernels/releases/download/v0.0.6/autoawq_kernels-0.0.6+cu118-cp310-cp310-linux_x86_64.whl (33.0 MB)\nRequirement already satisfied: torch>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from autoawq-kernels==0.0.6+cu118) (2.2.1+cu118)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq-kernels==0.0.6+cu118) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq-kernels==0.0.6+cu118) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq-kernels==0.0.6+cu118) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq-kernels==0.0.6+cu118) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq-kernels==0.0.6+cu118) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq-kernels==0.0.6+cu118) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq-kernels==0.0.6+cu118) (11.8.89)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq-kernels==0.0.6+cu118) (11.8.89)\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq-kernels==0.0.6+cu118) (11.8.87)\nRequirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq-kernels==0.0.6+cu118) (8.7.0.84)\nRequirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq-kernels==0.0.6+cu118) (11.11.3.6)\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq-kernels==0.0.6+cu118) (10.9.0.58)\nRequirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq-kernels==0.0.6+cu118) (10.3.0.86)\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq-kernels==0.0.6+cu118) (11.4.1.48)\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq-kernels==0.0.6+cu118) (11.7.5.86)\nRequirement already satisfied: nvidia-nccl-cu11==2.19.3 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq-kernels==0.0.6+cu118) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq-kernels==0.0.6+cu118) (11.8.86)\nRequirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq-kernels==0.0.6+cu118) (2.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.0.1->autoawq-kernels==0.0.6+cu118) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.0.1->autoawq-kernels==0.0.6+cu118) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install qwen-vl-utils","metadata":{"execution":{"iopub.status.busy":"2024-10-21T05:20:02.499552Z","iopub.execute_input":"2024-10-21T05:20:02.499907Z","iopub.status.idle":"2024-10-21T05:20:16.051513Z","shell.execute_reply.started":"2024-10-21T05:20:02.499871Z","shell.execute_reply":"2024-10-21T05:20:16.050598Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting qwen-vl-utils\n  Downloading qwen_vl_utils-0.0.8-py3-none-any.whl.metadata (3.6 kB)\nCollecting av (from qwen-vl-utils)\n  Downloading av-13.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from qwen-vl-utils) (21.3)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from qwen-vl-utils) (10.3.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from qwen-vl-utils) (2.32.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->qwen-vl-utils) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->qwen-vl-utils) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->qwen-vl-utils) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->qwen-vl-utils) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->qwen-vl-utils) (2024.8.30)\nDownloading qwen_vl_utils-0.0.8-py3-none-any.whl (5.9 kB)\nDownloading av-13.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: av, qwen-vl-utils\nSuccessfully installed av-13.1.0 qwen-vl-utils-0.0.8\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-10-21T05:20:16.052864Z","iopub.execute_input":"2024-10-21T05:20:16.053169Z","iopub.status.idle":"2024-10-21T05:20:17.148755Z","shell.execute_reply.started":"2024-10-21T05:20:16.053136Z","shell.execute_reply":"2024-10-21T05:20:17.147816Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Mon Oct 21 05:20:16 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   38C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   40C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\nfrom qwen_vl_utils import process_vision_info\n\n# default: Load the model on the available device(s)\n# model = Qwen2VLForConditionalGeneration.from_pretrained(\n#     \"Qwen/Qwen2-VL-7B-Instruct-AWQ\", torch_dtype=\"auto\", device_map=\"auto\"\n# )\n\n# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\nmodel = Qwen2VLForConditionalGeneration.from_pretrained(\n    \"Qwen/Qwen2-VL-7B-Instruct-AWQ\",\n    torch_dtype=torch.bfloat16,\n#     attn_implementation=\"flash_attention_2\",\n    device_map=\"auto\",\n)\n\n# default processer\n# processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct-AWQ\")\n\n# The default range for the number of visual tokens per image in the model is 4-16384. You can set min_pixels and max_pixels according to your needs, such as a token count range of 256-1280, to balance speed and memory usage.\nmin_pixels = 256*28*28\nmax_pixels = 256*28*28\nprocessor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct-AWQ\", min_pixels=min_pixels, max_pixels=max_pixels)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T05:20:17.150239Z","iopub.execute_input":"2024-10-21T05:20:17.150574Z","iopub.status.idle":"2024-10-21T05:21:28.269121Z","shell.execute_reply.started":"2024-10-21T05:20:17.150539Z","shell.execute_reply":"2024-10-21T05:21:28.268315Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.45k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5d4ad50d19943258a6829d361c9c400"}},"metadata":{}},{"name":"stderr","text":"We suggest you to set `torch_dtype=torch.float16` for better efficiency with AWQ.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/92.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53201ae24bbd40ed8904f5a604f912ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa87d900c18548a2afa4a1b4e2e7e92c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/3.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6de4daf59df44eb082a4da907f4d0724"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b1dadecfceb400e8a57399ae2142f28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"befea13914ed4f2590ba1ee0c69addca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/249 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd2836b749524011b47432f2bb99d6e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/567 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b85db2f587841349ea0d6f2e36d0506"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/4.30k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bacb23f521ee429f8d0b4ea6a3f7950c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d12060d3d7f34a8baf5907d13d6d12a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5877b933c0774f57999833fba5616312"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e045fb45e2ec473b8a015feef170365e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/392 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3ab7cc0c6b042f78e62022adbeb3906"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/613 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56a1187b8b124c6fbf7fbeb3a504e042"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"467580979143499b9cc5699a872b023d"}},"metadata":{}}]},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2024-10-21T05:28:31.792366Z","iopub.execute_input":"2024-10-21T05:28:31.792770Z","iopub.status.idle":"2024-10-21T05:28:31.797380Z","shell.execute_reply.started":"2024-10-21T05:28:31.792730Z","shell.execute_reply":"2024-10-21T05:28:31.796408Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"messages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"image\",\n                \"image\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\",\n            },\n            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n        ],\n    }\n]\nt1 = time.time()\n# Preparation for inference\ntext = processor.apply_chat_template(\n    messages, tokenize=False, add_generation_prompt=True\n)\nimage_inputs, video_inputs = process_vision_info(messages)\ninputs = processor(\n    text=[text],\n    images=image_inputs,\n    videos=video_inputs,\n    padding=True,\n    return_tensors=\"pt\",\n)\ninputs = inputs.to(\"cuda\")\nt2 = time.time()\n# Inference: Generation of the output\ngenerated_ids = model.generate(**inputs, max_new_tokens=128)\ngenerated_ids_trimmed = [\n    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n]\noutput_text = processor.batch_decode(\n    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n)\nt3 = time.time()\nprint(output_text)\nprint(\"time for preprocessing =\", t2-t1)\nprint(\"time for inference =\", t3-t2)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T05:29:40.813071Z","iopub.execute_input":"2024-10-21T05:29:40.813471Z","iopub.status.idle":"2024-10-21T05:29:51.059639Z","shell.execute_reply.started":"2024-10-21T05:29:40.813433Z","shell.execute_reply":"2024-10-21T05:29:51.058668Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"['The image shows a woman sitting on the beach with her dog. The woman is wearing a plaid shirt and appears to be enjoying a sunny day. The dog is sitting next to her, and they are both engaged in a playful activity, possibly giving each other high fives. The beach has sand and the ocean in the background, with waves gently rolling in. The overall atmosphere is relaxed and happy.']\ntime for preprocessing = 2.42995023727417\ntime for inference = 7.8075079917907715\n","output_type":"stream"}]}]}